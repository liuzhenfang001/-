# 秋招准备  
## 机器学习资源
机器学习模型可以分为两派：频率派和贝叶斯派  
频率派：逻辑回归，线性回归，SVM， Adaboost， XGBoost， LightGBM， KNN， K-means， Bagging, Boosting, 朴素贝叶斯，随机森林，GMM， 最大熵模型， PCA， LDA，SVD， 决策树  
贝叶斯派：EM， 马尔科夫随机场， 条件随机场， 隐马尔可夫模型（HMM），
### 1. 逻辑回归：https://zhuanlan.zhihu.com/p/74874291
  #### 为什么要加上一层SIGMOD函数？  
   答：线性模型（也可以是非线性模型，例如二次）的输出是连续的，不能很好的拟合分类（离散）问题。假设二分类，线性模型输出正，则判断为正例，负数则判断为负例，那么无法进行优化。加上SIGMOD，优化会尽可能的让模型输出正无穷或负无穷的值，例如使用MLE进行参数估计。另外，逻辑回归能预测出概率值，可以辅助决策。  
   #### 优化
   随机梯度下降SGD：迭代次数用完或者损失小于某个阈值则停止
#### 极大似然MLE估计参数
### 3. 线性回归
### 4. 
